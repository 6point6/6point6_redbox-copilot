{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "from enum import Enum\n",
    "from typing import List, Optional\n",
    "\n",
    "import dotenv\n",
    "from langchain.chains import create_extraction_chain\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.output_parsers import (\n",
    "    CommaSeparatedListOutputParser,\n",
    "    PydanticOutputParser,\n",
    "    RetryWithErrorOutputParser,\n",
    "    XMLOutputParser,\n",
    ")\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.vectorstores import Chroma\n",
    "from pydantic import (\n",
    "    BaseModel,\n",
    "    Field,\n",
    "    ValidationError,\n",
    "    computed_field,\n",
    "    create_model,\n",
    "    field_validator,\n",
    ")\n",
    "from pyprojroot import here\n",
    "\n",
    "from redbox.llm.llm_base import LLMHandler\n",
    "from redbox.models.classification import Tag, TagGroup\n",
    "from redbox.models.file import File\n",
    "\n",
    "ENV = dotenv.dotenv_values(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabet_iterator(alpha=string.ascii_lowercase):\n",
    "    letters = list(alpha)\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield letters[n]\n",
    "        n += 1\n",
    "        if n == len(letters):\n",
    "            n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = alphabet_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = list(string.ascii_lowercase)\n",
    "len(alpha)\n",
    "alpha[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(anthropic_api_key=ENV[\"ANTHROPIC_API_KEY\"])\n",
    "\n",
    "handler = LLMHandler(\n",
    "    llm=llm,\n",
    "    user_uuid=\"foo\",\n",
    "    vector_store=Chroma(\n",
    "        embedding_function=SentenceTransformerEmbeddings(),\n",
    "        persist_directory=\"../data/dev/db\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.join(here(), \"data\", \"dev\")\n",
    "parsed_files_folder = os.path.join(data_folder, \"file\")\n",
    "parsed_files = os.listdir(parsed_files_folder)\n",
    "parsed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, \"file\", parsed_files[0])) as f:\n",
    "    email = json.load(f)[\"text\"]\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[1])) as f:\n",
    "    speech = json.load(f)[\"text\"]\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[4])) as f:\n",
    "    submission = json.load(f)[\"text\"]\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[2])) as f:\n",
    "    minutes = json.load(f)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_regex = re.compile(r\"(?<=<answer>)(.*?)(?=<\\/answer>)\")\n",
    "alpha_regex = re.compile(\"[^a-zA-Z]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalising\n",
    "\n",
    "Going to try and make an object so anyone can make cusom layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, \"file\", parsed_files[0])) as f:\n",
    "    email = File(**json.load(f))\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[1])) as f:\n",
    "    speech = File(**json.load(f))\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[4])) as f:\n",
    "    submission = File(**json.load(f))\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[2])) as f:\n",
    "    minutes = File(**json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_category_dict = {\n",
    "    \"email\": {\n",
    "        \"letter\": \"a\",\n",
    "        \"description\": \"Email, letters and correspondance\",\n",
    "        \"examples\": [email],\n",
    "    },\n",
    "    \"speech\": {\"letter\": \"b\", \"description\": \"Speech\", \"examples\": [speech]},\n",
    "    \"minutes\": {\"letter\": \"c\", \"description\": \"Meeting minutes\", \"examples\": [speech]},\n",
    "    \"submission\": {\n",
    "        \"letter\": \"d\",\n",
    "        \"description\": \"Submission or proposal\",\n",
    "        \"examples\": [minutes],\n",
    "    },\n",
    "    \"other\": {\"letter\": \"e\", \"description\": \"Other, including documents\"},\n",
    "}\n",
    "\n",
    "format = TagGroup(name=\"format\", tags=[Tag(**v) for k, v in doc_category_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.classify_to_tag(\n",
    "    group=format,\n",
    "    raw_text=\"Dear Mr Sunak, please send the whole Civil Service LLMs for Christmas. Love, Will\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_doc_cat_example_template = PromptTemplate(\n",
    "    input_variables=[\"document\", \"answer\"],\n",
    "    template=\"\"\"\\\n",
    "        Document:\n",
    "        <document>\n",
    "        {document}\n",
    "        </document>\n",
    "        Assistant: My answer is {{{{'letter': '{answer}'}}}}\\\n",
    "    \"\"\",\n",
    ")\n",
    "\n",
    "_doc_cat_prefix_template = \"\"\"\\\n",
    "You are a customer service agent that is classifying documents. \\\n",
    "The document is wrapped in <document></document> XML tags.\n",
    "\n",
    "Categories are:\n",
    "\n",
    "{layer_list_items}\\\n",
    "\"\"\"\n",
    "\n",
    "_get_doc_subject_suffix = \"\"\"\\\n",
    "\n",
    "Here is the document, wrapped in <document></document> XML tags\n",
    "<document>\n",
    "{raw_text}\n",
    "</document>\n",
    "\n",
    "{format_instructions} \\\n",
    "\n",
    "Assistant: My answer is {{'letter': '\\\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Tag(BaseModel):\n",
    "    letter: str\n",
    "    description: str\n",
    "    examples: Optional[List[File]] = None\n",
    "\n",
    "    @field_validator(\"letter\")\n",
    "    @classmethod\n",
    "    def letter_to_upper(cls, v: str) -> str:\n",
    "        return v.upper()\n",
    "\n",
    "    @computed_field\n",
    "    def var(self) -> str:\n",
    "        alpha_regex = re.compile(\"[^a-zA-Z_]\")\n",
    "        space_to_score = self.description.replace(\" \", \"_\").lower()\n",
    "        return re.sub(alpha_regex, \"\", space_to_score)\n",
    "\n",
    "    def get_examples(self):\n",
    "        examples = []\n",
    "        for example in self.examples:\n",
    "            to_add = {\"document\": example.text, \"answer\": self.letter}\n",
    "            examples.append(to_add)\n",
    "        return examples\n",
    "\n",
    "    def get_list_item(self):\n",
    "        return f\"({self.letter}) {self.description}\"\n",
    "\n",
    "\n",
    "class TagGroup(BaseModel):\n",
    "    name: str\n",
    "    tags: List[Tag]\n",
    "\n",
    "    def get_examples(self):\n",
    "        examples = []\n",
    "        for tag in self.tags:\n",
    "            if tag.examples is not None:\n",
    "                examples += tag.get_examples()\n",
    "        return examples\n",
    "\n",
    "    def get_list_items(self):\n",
    "        list_items = \"\"\n",
    "        for tag in self.tags:\n",
    "            list_items += tag.get_list_item() + \" \\n\"\n",
    "        return list_items\n",
    "\n",
    "    def get_letters(self):\n",
    "        return [tag.letter for tag in self.tags]\n",
    "\n",
    "    def make_validator(self):\n",
    "        def letter_validator(cls, v):\n",
    "            assert v in self.get_letters(), description\n",
    "            return v\n",
    "\n",
    "        description = (\n",
    "            \"Must be a single uppercase letter of the alphabet corresponding \"\n",
    "            \"to one of the following: \\n\\n\"\n",
    "            f\"{self.get_list_items()}\"\n",
    "        )\n",
    "\n",
    "        validators = {\"letter_validator\": field_validator(\"letter\")(letter_validator)}\n",
    "\n",
    "        return create_model(self.name, letter=(str, ...), __validators__=validators)\n",
    "\n",
    "    def get_tag(self, letter):\n",
    "        validator = self.make_validator()\n",
    "        validator(letter=letter)\n",
    "        for tag in self.tags:\n",
    "            if tag.letter == letter:\n",
    "                return tag\n",
    "\n",
    "    def get_parser(self):\n",
    "        return PydanticOutputParser(pydantic_object=self.make_validator())\n",
    "\n",
    "    def get_classification_prompt_template(self, parser=None):\n",
    "        if parser is None:\n",
    "            parser = self.get_parser()\n",
    "\n",
    "        return FewShotPromptTemplate(\n",
    "            examples=self.get_examples(),\n",
    "            example_prompt=_doc_cat_example_template,\n",
    "            prefix=_doc_cat_prefix_template,\n",
    "            suffix=_get_doc_subject_suffix,\n",
    "            input_variables=[\"raw_text\"],\n",
    "            partial_variables={\n",
    "                \"layer_list_items\": self.get_list_items(),\n",
    "                \"format_instructions\": parser.get_format_instructions(),\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_category_dict = {\n",
    "    \"email\": {\n",
    "        \"letter\": \"a\",\n",
    "        \"description\": \"Email, letters and correspondance\",\n",
    "        \"examples\": [email],\n",
    "    },\n",
    "    \"speech\": {\"letter\": \"b\", \"description\": \"Speech\", \"examples\": [speech]},\n",
    "    \"minutes\": {\"letter\": \"c\", \"description\": \"Meeting minutes\", \"examples\": [speech]},\n",
    "    \"submission\": {\n",
    "        \"letter\": \"d\",\n",
    "        \"description\": \"Submission or proposal\",\n",
    "        \"examples\": [minutes],\n",
    "    },\n",
    "    \"other\": {\"letter\": \"e\", \"description\": \"Other, including documents\"},\n",
    "}\n",
    "\n",
    "format = TagGroup(name=\"format\", tags=[Tag(**v) for k, v in doc_category_dict.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = format.get_parser()\n",
    "prompt = format.get_classification_prompt_template()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_prompt = prompt.format_prompt(\n",
    "    raw_text=\"Dear Santa, this is my email. Love William\"\n",
    ")\n",
    "attempt_count_max = 5\n",
    "\n",
    "try:\n",
    "    output = llm([HumanMessage(content=input_prompt.text)])\n",
    "    detected_class = parser.parse(output.content)\n",
    "except ValueError as parse_error:\n",
    "    print(\n",
    "        f\"Encountered error with first metadata extraction attempt: {str(parse_error)}\"\n",
    "    )\n",
    "    attempt_count = 0\n",
    "\n",
    "    retry_parser = RetryWithErrorOutputParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "    metadata = None\n",
    "\n",
    "    while attempt_count < attempt_count_max:\n",
    "        try:\n",
    "            detected_class = retry_parser.parse_with_prompt(\n",
    "                completion=output.content, prompt_value=input_prompt\n",
    "            )\n",
    "            break\n",
    "        except ValueError as parse_retry_errror:\n",
    "            print(f\"Failed to rectify malformed data object: {str(parse_retry_errror)}\")\n",
    "            attempt_count += 1\n",
    "\n",
    "    if detected_class is not None:\n",
    "        print(f\"Sucessful extraction with {attempt_count+1} attempt(s)\")\n",
    "    else:\n",
    "        print(f\"Failed extraction with {attempt_count+1} attempt(s)\")\n",
    "\n",
    "my_tag = format.get_tag(detected_class.letter)\n",
    "print(my_tag.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc format experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(email, type=\"format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(email, type=\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = XMLOutputParser(tags=[\"answer\"])\n",
    "\n",
    "to_send = HumanMessage(\n",
    "    content=GET_DOCTYPE_PROMPT.format_prompt(raw_text=email).to_string()\n",
    ")\n",
    "\n",
    "result = llm([to_send])\n",
    "\n",
    "result.content\n",
    "\n",
    "answer_regex = re.compile(r\"(?<=<answer>)(.*?)(?=<\\/answer>)\")\n",
    "alpha_regex = re.compile(\"[^a-zA-Z ]\")\n",
    "\n",
    "all_answers = re.findall(answer_regex, result.content)\n",
    "\n",
    "if len(all_answers) == 0:\n",
    "    raise Exception(\n",
    "        f\"\"\"\n",
    "        No answer detected in response:\n",
    "        {result.content}\n",
    "    \"\"\"\n",
    "    )\n",
    "\n",
    "out = all_answers[0].split(\")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = [alpha_regex.sub(\"\", i.strip()) for i in out]\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DocType(category=out[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(speech, type=\"format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(speech, type=\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_send = HumanMessage(\n",
    "    content=GET_DOCTYPE_PROMPT.format_prompt(raw_text=speech).to_string()\n",
    ")\n",
    "\n",
    "result = llm([to_send])\n",
    "\n",
    "res = re.findall(answer_regex, result.content)\n",
    "\n",
    "letter, description = res[0].split(\")\")\n",
    "letter = alpha_regex.sub(\"\", letter)\n",
    "description = description.strip()\n",
    "\n",
    "(letter, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(submission, type=\"format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(submission, type=\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_send = HumanMessage(\n",
    "    content=GET_DOCTYPE_PROMPT.format_prompt(raw_text=submission).to_string()\n",
    ")\n",
    "\n",
    "result = llm([to_send])\n",
    "\n",
    "res = re.findall(answer_regex, result.content)\n",
    "\n",
    "letter, description = res[0].split(\")\")\n",
    "letter = alpha_regex.sub(\"\", letter)\n",
    "description = description.strip()\n",
    "\n",
    "(letter, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(minutes, type=\"format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.get_doc_category(minutes, type=\"subject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_send = HumanMessage(\n",
    "    content=GET_DOCTYPE_PROMPT.format_prompt(raw_text=minutes).to_string()\n",
    ")\n",
    "\n",
    "result = llm([to_send])\n",
    "\n",
    "res = re.findall(answer_regex, result.content)\n",
    "\n",
    "letter, description = res[0].split(\")\")\n",
    "letter = alpha_regex.sub(\"\", letter)\n",
    "description = description.strip()\n",
    "\n",
    "(letter, description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DocCategory(Enum):\n",
    "    email = \"email\"\n",
    "    speech = \"speech\"\n",
    "    minutes = \"minutes\"\n",
    "    submission = \"submission\"\n",
    "\n",
    "\n",
    "class DocType(BaseModel):\n",
    "    category: DocCategory\n",
    "\n",
    "    @field_validator(\"category\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def _flexible_cat(cls, v: str) -> str:\n",
    "        v = v.lower().strip()\n",
    "        if v in [\"a\", \"emails\"]:\n",
    "            return \"email\"\n",
    "        elif v in [\"b\", \"speeches\"]:\n",
    "            return \"speech\"\n",
    "        elif v in [\"c\", \"minute\", \"meetng\", \"meeting minutes\"]:\n",
    "            return \"minutes\"\n",
    "        elif v in [\"c\", \"submissions\"]:\n",
    "            return \"submission\"\n",
    "        else:\n",
    "            return v\n",
    "\n",
    "\n",
    "doctype_parser = PydanticOutputParser(pydantic_object=DocType)\n",
    "\n",
    "retry_parser = RetryWithErrorOutputParser.from_llm(parser=doctype_parser, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_retry(attempt_count_max: int = 5):\n",
    "    def inner(func):\n",
    "        def func_with_retry(*args, **kwargs):\n",
    "            attempt_count = 0\n",
    "\n",
    "            success = False\n",
    "\n",
    "            while attempt_count < attempt_count_max and not success:\n",
    "                try:\n",
    "                    res = func(*args, **kwargs)\n",
    "                    success = True\n",
    "                except ValueError as e:\n",
    "                    print(f\"Failed to rectify malformed data object: {str(e)}\")\n",
    "                    attempt_count += 1\n",
    "\n",
    "            if res is not None:\n",
    "                print(f\"Sucessful extraction with {attempt_count+1} attempt(s)\")\n",
    "            else:\n",
    "                print(f\"Failed extraction with {attempt_count+1} attempt(s)\")\n",
    "\n",
    "            return res\n",
    "\n",
    "        return func_with_retry\n",
    "\n",
    "    return inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@try_retry(attempt_count_max=5)\n",
    "def get_doctype(raw_text):\n",
    "    to_send = HumanMessage(\n",
    "        content=GET_DOCTYPE_PROMPT.format_prompt(raw_text=raw_text).to_string()\n",
    "    )\n",
    "    result = llm([to_send])\n",
    "\n",
    "    answer_regex = re.compile(r\"(?<=<answer>)(.*?)(?=<\\/answer>)\")\n",
    "    alpha_regex = re.compile(\"[^a-zA-Z ]\")\n",
    "\n",
    "    all_answers = re.findall(answer_regex, result.content.replace(\"\\n\", \"\"))\n",
    "\n",
    "    if len(all_answers) == 0:\n",
    "        raise ValueError(\n",
    "            f\"\"\"\n",
    "            No answer detected in response:\n",
    "            {result.content}\n",
    "        \"\"\"\n",
    "        )\n",
    "\n",
    "    out = all_answers[0].split(\")\")\n",
    "\n",
    "    if len(out) == 0:\n",
    "        raise ValueError(\"No category detected\")\n",
    "\n",
    "    out = [alpha_regex.sub(\"\", i.strip()) for i in out]\n",
    "\n",
    "    for i in out:\n",
    "        try:\n",
    "            res = DocType(category=i)\n",
    "            return res\n",
    "        except ValidationError:\n",
    "            continue\n",
    "\n",
    "    raise ValueError(\"No category detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_doctype(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_doctype(\n",
    "    \"Dear Caolm, here is my text I am sending you. Please forweard it to my mumn, love Will\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc subject experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
