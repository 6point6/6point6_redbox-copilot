{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import dotenv\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.output_parsers import RetryWithErrorOutputParser\n",
    "from langchain.vectorstores import Chroma\n",
    "from pyprojroot import here\n",
    "\n",
    "from redbox.llm.llm_base import LLMHandler\n",
    "from redbox.models.classification import Tag, TagGroup\n",
    "from redbox.models.file import File\n",
    "\n",
    "ENV = dotenv.dotenv_values(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatAnthropic(anthropic_api_key=ENV[\"ANTHROPIC_API_KEY\"])\n",
    "\n",
    "handler = LLMHandler(\n",
    "    llm=llm,\n",
    "    user_uuid=\"foo\",\n",
    "    vector_store=Chroma(\n",
    "        embedding_function=SentenceTransformerEmbeddings(),\n",
    "        persist_directory=\"../data/dev/db\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "data_folder = os.path.join(here(), \"data\", \"dev\")\n",
    "parsed_files_folder = os.path.join(data_folder, \"file\")\n",
    "parsed_files = os.listdir(parsed_files_folder)\n",
    "user_prefs_folder = os.path.join(here(), \"data\", \"dev\", \"user_preferences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(data_folder, \"file\", parsed_files[0])) as f:\n",
    "    email = File(**json.load(f))\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[1])) as f:\n",
    "    speech = File(**json.load(f))\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[4])) as f:\n",
    "    submission = File(**json.load(f))\n",
    "\n",
    "with open(os.path.join(data_folder, \"file\", parsed_files[2])) as f:\n",
    "    minutes = File(**json.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_taggroups = []\n",
    "for user_pref in os.listdir(user_prefs_folder):\n",
    "    with open(os.path.join(user_prefs_folder, user_pref)) as f:\n",
    "        user_taggroups.append(TagGroup(**json.load(f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handler.classify_to_tag(group=user_taggroups[0], raw_text=minutes.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = user_taggroups[0]\n",
    "raw_text = minutes.text\n",
    "attempt_count_max = 5\n",
    "\n",
    "parser = group.get_parser()\n",
    "prompt = group.get_classification_prompt_template()\n",
    "\n",
    "input_prompt = prompt.format_prompt(raw_text=raw_text)\n",
    "\n",
    "try:\n",
    "    output = llm([HumanMessage(content=input_prompt.text)])\n",
    "    detected_class = parser.parse(output.content)\n",
    "except ValueError as parse_error:\n",
    "    print(\n",
    "        f\"Encountered error with first metadata extraction attempt: {str(parse_error)}\"\n",
    "    )\n",
    "    attempt_count = 0\n",
    "\n",
    "    retry_parser = RetryWithErrorOutputParser.from_llm(parser=parser, llm=llm)\n",
    "\n",
    "    detected_class = None\n",
    "\n",
    "    while attempt_count < attempt_count_max:\n",
    "        try:\n",
    "            detected_class = retry_parser.parse_with_prompt(\n",
    "                completion=output.content, prompt_value=input_prompt\n",
    "            )\n",
    "            break\n",
    "        except ValueError as parse_retry_errror:\n",
    "            print(f\"Failed to rectify malformed data object: {str(parse_retry_errror)}\")\n",
    "            attempt_count += 1\n",
    "\n",
    "    if detected_class is not None:\n",
    "        print(f\"Sucessful extraction with {attempt_count+1} attempt(s)\")\n",
    "    else:\n",
    "        print(f\"Failed extraction with {attempt_count+1} attempt(s)\")\n",
    "\n",
    "my_tag = group.get_tag(detected_class.letter)\n",
    "\n",
    "Tag(letter=my_tag.letter, description=my_tag.description)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
