{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date\n",
    "\n",
    "from langchain.cache import SQLiteCache\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain.vectorstores import Chroma\n",
    "from pyprojroot import here\n",
    "\n",
    "from redbox.llm.prompts.chat import (\n",
    "    CONDENSE_QUESTION_PROMPT,\n",
    "    STUFF_DOCUMENT_PROMPT,\n",
    "    WITH_SOURCES_PROMPT,\n",
    ")\n",
    "\n",
    "vector_store = Chroma(\n",
    "    embedding_function=SentenceTransformerEmbeddings(),\n",
    "    persist_directory=\"../data/db/\",\n",
    ")\n",
    "\n",
    "test_user_info = {\n",
    "    \"name\": \"Liam Wilkinson\",\n",
    "    \"email\": \"liam.wilkinson@cabinetoffice.gov.uk\",\n",
    "    \"department\": \"Cabinet Office\",\n",
    "    \"role\": \"Economic Policy\",\n",
    "    \"preferred_language\": \"British English\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SQLiteCache(database_path=os.path.join(here(), os.environ[\"CACHE_LLM_DB\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_llm_cache(\n",
    "    SQLiteCache(database_path=os.path.join(here(), os.environ[\"CACHE_LLM_DB\"]))\n",
    ")\n",
    "\n",
    "llm = ChatAnthropic(anthropic_api_key=os.environ[\"ANTHROPIC_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [HumanMessage(content=\"Tell me a better joke\")]\n",
    "\n",
    "llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = [\n",
    "    HumanMessage(\n",
    "        content=\"You're an expert in geography. Answer geographical questions with authority.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "user_question = [HumanMessage(content=\"What is the capital of Spain?\")]\n",
    "\n",
    "docs_with_sources_chain = load_qa_with_sources_chain(\n",
    "    llm,\n",
    "    chain_type=\"stuff\",\n",
    "    prompt=WITH_SOURCES_PROMPT,\n",
    "    document_prompt=STUFF_DOCUMENT_PROMPT,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "condense_question_chain = LLMChain(llm=llm, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "\n",
    "# split chain manualy, so that the standalone question doesn't leak into chat\n",
    "# should we display some waiting message instead?\n",
    "standalone_question = condense_question_chain(\n",
    "    {\n",
    "        \"question\": user_question,\n",
    "        \"chat_history\": chat_history,\n",
    "        # \"user_info\": user_info,\n",
    "        # \"current_datetime\": datetime.now().isoformat()\n",
    "    }\n",
    ")[\"text\"]\n",
    "\n",
    "docs = vector_store.as_retriever().get_relevant_documents(\n",
    "    standalone_question,\n",
    ")\n",
    "\n",
    "result = docs_with_sources_chain(\n",
    "    {\n",
    "        \"question\": standalone_question,\n",
    "        \"input_documents\": docs,\n",
    "        \"user_info\": test_user_info,\n",
    "        \"current_date\": date.today().isoformat(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date.today().isoformat()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
